{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c03992-85be-45ae-a72d-9d1472d6c76e",
   "metadata": {},
   "source": [
    "### Wordnet Lemmatizer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e716d-cea1-494a-873a-d4409e456e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemmatization is a Natural Language Processing (NLP) technique that reduces words to their meaningful base or \n",
    "dictionary form (lemma) by analyzing context and part-of-speech (POS), unlike stemming, \n",
    "which just chops off endings, making itmore accurate for tasks like chatbots, search engines, and text analysis by grouping \n",
    "variations like \"running,\" \"runs,\" \"ran\" into \"run,\" or \"better\" into \"good\" (as an adjective). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a30ac-a70b-455d-8d03-d1b99d46f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The WordNet Lemmatizer is a tool, most notably available within the Python NLTK (Natural Language Toolkit) library, \n",
    "that uses the English WordNet lexical database to reduce words to their base or dictionary form, known as a lemma.\n",
    "This process, called lemmatization, ensures the resulting word is a valid and meaningful English word, unlike stemming, \n",
    "which simply chops off word endings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "326f24b9-4187-4ea5-902a-6282e07c312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q&A,chatbots, text summarization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539ced7d-03a0-4911-8be1-e08cc8335a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/pandeyraj/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fab4873-28ed-41b1-be4b-49f1b29c2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe7d231-494a-4af0-bb2b-98b8a0563863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "POS- Noun-n\n",
    "verb-v\n",
    "adjective-a\n",
    "adverb-r\n",
    "'''\n",
    "lemmatizer.lemmatize(\"going\",pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a4b09a-847b-4581-a71a-8241c90868ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44cc4677-fdc1-4b00-8675-c9d83c5ec169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "866bfaa6-cebd-407a-a225-ac0afc0019d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5231a057-80ae-4d67-9642-440adfd4fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49fdbf7e-c1c2-466e-82c4-086b9b69bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eating\n",
      "eats----->eats\n",
      "eaten----->eaten\n",
      "writing----->writing\n",
      "writes----->writes\n",
      "programming----->programming\n",
      "history----->history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "     print(word+\"----->\"+lemmatizer.lemmatize(word,pos='n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d8066cb-cf86-490b-8288-96292af4c39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eating\n",
      "eats----->eats\n",
      "eaten----->eaten\n",
      "writing----->writing\n",
      "writes----->writes\n",
      "programming----->programming\n",
      "history----->history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "     print(word+\"----->\"+lemmatizer.lemmatize(word,pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1faa4ea6-532f-46cf-9d7b-6572ab21be88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eat\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "history----->history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "     print(word+\"----->\"+lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "546b3f9e-904f-4c22-ad02-41bc60cb9f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"goes\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d79738-ae02-4c41-bce3-c459e462ef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'sportingly')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"fairly\",pos='v'),lemmatizer.lemmatize(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0b031-b45b-4d91-b709-a4a2adcb7fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
